{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# SQL related packages\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "# sklearn packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression as Log\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "# text analysis packages\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# access to sql database\n",
    "dbname = 'patent_db'\n",
    "username = 'jy'\n",
    "pswd = 'jy'\n",
    "\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "\n",
    "# reading from sql database\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract abstracts first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12033, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from 2004-2007\n",
    "years = np.arange(2004, 2008)\n",
    "\n",
    "# dataframe to store the results\n",
    "abstracts = pd.DataFrame()\n",
    "\n",
    "# import the abstract from each table\n",
    "for year in years:\n",
    "    # query:\n",
    "    sql_query = \"\"\"\n",
    "    SELECT abstract, id, payment_times\n",
    "        FROM patents_%s;\n",
    "    \"\"\" %str(year)\n",
    "\n",
    "    results = pd.read_sql_query(sql_query,con)\n",
    "    \n",
    "    abstracts = pd.concat([abstracts, results], axis = 0)\n",
    "    \n",
    "# check size of the data\n",
    "abstracts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patents with > 1 maintenance fee payments:  0.628521565694\n"
     ]
    }
   ],
   "source": [
    "# extract the response variable\n",
    "# reformat the response variable into binary\n",
    "y_data = np.zeros(abstracts.shape[0])\n",
    "y_data[abstracts['payment_times'].values >= 2] = 1\n",
    "\n",
    "print \"Percentage of patents with > 1 maintenance fee payments: \", np.mean(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spliting train-test data first\n",
    "Perform tokenization and other preprocessing on the training data alone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "x_train:  (9626,)\n",
      "x_test:  (2407,)\n",
      "y_train:  (9626,)\n",
      "y_test:  (2407,)\n"
     ]
    }
   ],
   "source": [
    "x_data = abstracts['abstract'].values\n",
    "\n",
    "# split train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "print \"Dataset dimensions:\"\n",
    "print \"x_train: \", x_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"y_test: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def tokenize_cleaning(text):\n",
    "    # tokenize the text first\n",
    "    tokens = word_tokenize(text.decode('utf-8'))\n",
    "    \n",
    "    # lowercase all the words\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # clean up stop words and punctuations \n",
    "    stop_list = stopwords.words('english') + list(string.punctuation)\n",
    "\n",
    "    tokens_no_stop = [token for token in tokens\n",
    "                        if token not in stop_list]            \n",
    "    \n",
    "#     # extract stem of the words\n",
    "#     stemmer = PorterStemmer()\n",
    "#     tokens_stem = [stemmer.stem(token) for token in tokens_no_stop]\n",
    "\n",
    "    # use lemma instead\n",
    "    # reason: remove the influence of plural or tense\n",
    "    # but retain the subtle difference in legal writting\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lemma = [lemmatizer.lemmatize(token) for token in tokens_no_stop]\n",
    "    \n",
    "    # remove numbers (the actual values are not useful)\n",
    "    tokens_no_num = []\n",
    "    for token in tokens_lemma:\n",
    "        try:\n",
    "            float(token)\n",
    "        except:\n",
    "            tokens_no_num.append(token)\n",
    "    \n",
    "    return tokens_no_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize_clean the training text and testing text separately\n",
    "\n",
    "cleaned_train = []\n",
    "for i in range(x_train.shape[0]):\n",
    "    tokens = tokenize_cleaning(x_train[i])\n",
    "    cleaned_train.append(' '.join(word for word in tokens))\n",
    "    \n",
    "cleaned_test = []\n",
    "for i in range(x_test.shape[0]):\n",
    "    tokens = tokenize_cleaning(x_test[i])\n",
    "    cleaned_test.append(' '.join(word for word in tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training counts dimension:  (9626, 13432)\n",
      "Testing counts dimension:  (2407, 13432)\n"
     ]
    }
   ],
   "source": [
    "# convert to bag-of-words\n",
    "# min number selected by examining the low-frequency words\n",
    "vectorizer = CountVectorizer(max_df = 0.5, min_df=2)\n",
    "\n",
    "# perform a count-based vectorization of the document\n",
    "word_vec = vectorizer.fit(cleaned_train)\n",
    "word_counts_train = word_vec.transform(cleaned_train)\n",
    "word_counts_test = word_vec.transform(cleaned_test)\n",
    "\n",
    "# convert to array\n",
    "word_counts_train = word_counts_train.toarray()\n",
    "word_counts_test = word_counts_test.toarray()\n",
    "\n",
    "print \"Training counts dimension: \", word_counts_train.shape\n",
    "print \"Testing counts dimension: \", word_counts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical words detected:  358\n",
      "Training counts dimension:  (9626, 13074)\n",
      "Testing counts dimension:  (2407, 13074)\n"
     ]
    }
   ],
   "source": [
    "# still need to remove some number words \n",
    "# due to how CountVectorizer treats '-' and '/'\n",
    "\n",
    "# remove any word with numbers in it\n",
    "words = word_vec.get_feature_names()\n",
    "num_word_index = np.zeros(len(words))\n",
    "\n",
    "for i in range(len(words)):\n",
    "    word = words[i]\n",
    "    for j in range(len(word)):\n",
    "        try:\n",
    "            float(word[j])\n",
    "            num_word_index[i] = 1\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print \"Number of numerical words detected: \", int(np.sum(num_word_index))\n",
    "\n",
    "# remove the number words\n",
    "words_no_num = np.asarray(words)[num_word_index == 0]\n",
    "word_counts_train = word_counts_train[:, num_word_index == 0]\n",
    "word_counts_test = word_counts_test[:, num_word_index == 0]\n",
    "\n",
    "print \"Training counts dimension: \", word_counts_train.shape\n",
    "print \"Testing counts dimension: \", word_counts_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # check the distribution of word occurance\n",
    "# total_counts = np.sum(word_counts, axis = 0)\n",
    "# #plt.hist(np.transpose(total_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # inspect the words\n",
    "# df = pd.DataFrame({\n",
    "#     'word': words_no_num,\n",
    "#     'count': total_counts\n",
    "# })\n",
    "\n",
    "# df.sort('count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9626, 24551)\n"
     ]
    }
   ],
   "source": [
    "# apply IF-IDF\n",
    "tf_vectorizer = TfidfVectorizer()\n",
    "tf_vec = tf_vectorizer.fit(cleaned_train)\n",
    "tfidf_train = tf_vec.transform(cleaned_train)\n",
    "tfidf_test = tf_vec.transform(cleaned_test)\n",
    "# convert to array\n",
    "tfidf_train = tfidf_train.toarray()\n",
    "tfidf_test = tfidf_test.toarray()\n",
    "\n",
    "print tfidf_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7136, 24551)\n",
      "(7136,)\n"
     ]
    }
   ],
   "source": [
    "### subsampling the training data\n",
    "# sample the same number of'useful' patents as the 'not useful' patents\n",
    "# size of each class\n",
    "num_size = np.sum(y_train == 0)\n",
    "\n",
    "#random shuffle the rows\n",
    "n = tfidf_train.shape[0]\n",
    "perm = range(n)\n",
    "np.random.shuffle(perm)\n",
    "\n",
    "tfidf_train = tfidf_train[perm]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# separate the two classes\n",
    "x_useful = tfidf_train[y_train == 1, :]\n",
    "x_not_useful = tfidf_train[y_train == 0, :]\n",
    "y_useful = y_train[y_train == 1]\n",
    "y_not_useful = y_train[y_train == 0]\n",
    "\n",
    "# sample num_size from the 'useful' class\n",
    "x_useful = x_useful[:num_size, :]\n",
    "y_useful = y_useful[:num_size]\n",
    "\n",
    "# combine the two classes\n",
    "x_train_sub = np.concatenate((x_useful, x_not_useful), axis = 0)\n",
    "y_train_sub = np.concatenate((y_useful, y_not_useful), axis = 0)\n",
    "\n",
    "# shuffle again\n",
    "# shuffle the combined data\n",
    "n2 = x_train_sub.shape[0]\n",
    "perm2 = range(n2)\n",
    "np.random.shuffle(perm2)\n",
    "\n",
    "x_train_sub = x_train_sub[perm2]\n",
    "y_train_sub = y_train_sub[perm2]\n",
    "\n",
    "# check the size\n",
    "print x_train_sub.shape\n",
    "print y_train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy/anaconda2/envs/my_projects_env/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# # standardize the predictors\n",
    "# scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# x_train_std = scaler.fit_transform(x_train_sub)\n",
    "# x_test_std = scaler.transform(word_counts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy:  0.504777731616\n",
      "Confustion matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[475, 427],\n",
       "       [765, 740]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try Naive Bayes with Gaussian Distribution\n",
    "# no need to normalize for it\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# fit on the training data\n",
    "gnb.fit(x_train_sub, y_train_sub)\n",
    "\n",
    "# predict on the test data\n",
    "y_pred = gnb.predict(tfidf_test)\n",
    "\n",
    "# accuracy\n",
    "print \"Testing accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"Confustion matrix:\"\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try dimensionality reduction using PCA\n",
    "pca = PCA()\n",
    "\n",
    "x_train_pca = pca.fit_transform(x_train_sub)\n",
    "x_test_pca = pca.transform(tfidf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs that can explain > 90% variability:  3439\n"
     ]
    }
   ],
   "source": [
    "# find the cum-variance explained at each PC\n",
    "total_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_pc = np.where((total_var > 0.9) == True)[0][0]\n",
    "\n",
    "print \"The number of PCs that can explain > 90% variability: \", n_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### use logistic regression\n",
    "\n",
    "# call the model function\n",
    "model = Log()\n",
    "# parameter tuning\n",
    "c =  np.logspace(-4, 4, 9)\n",
    "\n",
    "# use grid search with 5-fold CV\n",
    "grid_model = GridSearchCV(model, param_grid = {'C': c}, cv  = 5, scoring = 'accuracy')\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca[:, :n_pc], y_train_sub) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.497197309417\n",
      "Best parameter:  {'C': 1000.0}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.479434981305\n",
      "F1 score:  0.534373838722\n",
      "Precision:  0.606239460371\n",
      "Recall:  0.477740863787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[435, 467],\n",
       "       [786, 719]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_log = grid_model.best_estimator_\n",
    "best_log.fit(x_train_pca[:, :n_pc], y_train_sub)\n",
    "y_pred = best_log.predict(x_test_pca[:, :n_pc])\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### tune random forest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(10, 80, 10)\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space}, \n",
    "                          cv  = 5, scoring = 'accuracy')\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca[:, :n_pc], y_train_sub)\n",
    "#grid_model = grid_model.fit(x_train_sub, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.502802690583\n",
      "Best parameter:  {'max_features': 60}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.510178645617\n",
      "F1 score:  0.559252336449\n",
      "Precision:  0.639316239316\n",
      "Recall:  0.497009966777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[480, 422],\n",
       "       [757, 748]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_pca[:, :n_pc], y_train_sub)\n",
    "y_pred = best_rf.predict(x_test_pca[:, :n_pc])\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try word2vec, meaning on the document level;\n",
    "can combine text features with non-text features\n",
    "\n",
    "\n",
    "## NLP: \n",
    "text to number;\n",
    "\n",
    "### BAG-OF-WORDS approach:\n",
    "TF-IDF: scale the numbers;\n",
    "you can hard code some key words as features, otherwise IF-IDF may decrease performance.\n",
    "\n",
    "**Topic modeling**: only at the document level\n",
    "Each document is a distribution over topics; each topic is a distribution over terms/words.\n",
    "Matrix: rows are documents, columns are topics, row sum up to 1.\n",
    "Topics: matirx as well. But you need to assign topic label to train the model. Need to set the number of topics. \n",
    "Basic model: LDA (latent Dirichlet)\n",
    "\n",
    "### WORD2VEC (word embedding, there is also GLOVE)\n",
    "Gensin is the library to use!\n",
    "spxy (harder to learn)\n",
    "NLTK (not great but easy to use)\n",
    "\n",
    "continuous bag-of-words, or the other method to predict the word\n",
    "\n",
    "there are pretrained models on Google news or wikipedia\n",
    "\n",
    "Can do manual inspection to check the models\n",
    "\n",
    "features: numbers representing the word/doc meaning \n",
    "\n",
    "to documents: take sum or mean as the features\n",
    "\n",
    "**Doc2vec**: document level, or summarize the key words and do word2vec\n",
    "\n",
    "shuffle the order of sentenses and train the model again, if corpus is very small. \n",
    "\n",
    "can pick up spelling problems.\n",
    "\n",
    "Gensin takes list of lists\n",
    "\n",
    "PROCESSES:\n",
    "smaller corpus requires more preprocessing;\n",
    "1. split sentenses/words\n",
    "2. stemming (large documents do not care much)\n",
    "3. stop words\n",
    "4. punctuation: ', \", \n",
    "5. numbers (no need to remove does not need to touch it)\n",
    "6. lowercase everything\n",
    "\n",
    "other features to consider: how long the patent is. it is easier to interpret. \n",
    "\n",
    "tSNE is preferred over PCA on text analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
