{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "# SQL related packages\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "# sklearn packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression as Log\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "# text analysis packages\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from gensim.models import word2vec, Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# access to sql database\n",
    "dbname = 'patent_db'\n",
    "username = 'jy'\n",
    "pswd = 'jy'\n",
    "\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "\n",
    "# reading from sql database\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12033, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from 2004-2007\n",
    "years = np.arange(2004, 2008)\n",
    "\n",
    "# dataframe to store the results\n",
    "claims = pd.DataFrame()\n",
    "\n",
    "# import the abstract from each table\n",
    "for year in years:\n",
    "    # query:\n",
    "    sql_query = \"\"\"\n",
    "    SELECT claims, id, payment_times, classification\n",
    "        FROM patents_%s;\n",
    "    \"\"\" %str(year)\n",
    "\n",
    "    results = pd.read_sql_query(sql_query,con)\n",
    "    \n",
    "    claims = pd.concat([claims, results], axis = 0)\n",
    "    \n",
    "# check size of the data\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patents with > 1 maintenance fee payments:  0.628521565694\n"
     ]
    }
   ],
   "source": [
    "# extract the response variable\n",
    "# reformat the response variable into binary\n",
    "y_data = np.zeros(claims.shape[0])\n",
    "y_data[claims['payment_times'].values >= 2] = 1\n",
    "\n",
    "print \"Percentage of patents with > 1 maintenance fee payments: \", np.mean(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the patents missing classification data\n",
    "missing_class_index = (claims['classification'].values == 'NA')\n",
    "\n",
    "# reassign patent index\n",
    "claims.index = range(len(claims.index))\n",
    "# drop the rows\n",
    "claims =  claims.drop(claims.index[missing_class_index])\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data[claims['classification'].values != 'NA']\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "x_train:  (10030, 4)\n",
      "x_test:  (2000, 4)\n",
      "y_train:  (10030,)\n",
      "y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "# split train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(claims, y_data[:claims.shape[0]], \n",
    "                                                    test_size = 2000, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "print \"Dataset dimensions:\"\n",
    "print \"x_train: \", x_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"y_test: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x_train will be combined with additional patent claims data to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11172, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from 2008-2010\n",
    "years = np.arange(2008, 2011)\n",
    "\n",
    "# dataframe to store the results\n",
    "claims = pd.DataFrame()\n",
    "\n",
    "# import the abstract from each table\n",
    "for year in years:\n",
    "    # query:\n",
    "    sql_query = \"\"\"\n",
    "    SELECT claims, id, payment_times, classification\n",
    "        FROM patents_%s;\n",
    "    \"\"\" %str(year)\n",
    "\n",
    "    results = pd.read_sql_query(sql_query,con)\n",
    "    \n",
    "    claims = pd.concat([claims, results], axis = 0)\n",
    "    \n",
    "# check size of the data\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine new claims with x_train\n",
    "train_data = pd.concat([x_train, claims], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_cleaning(text):\n",
    "    # tokenize the text first\n",
    "    tokens = word_tokenize(text.decode('utf-8'))\n",
    "    \n",
    "    # lowercase all the words\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # clean up stop words and punctuations \n",
    "    stop_list = stopwords.words('english') + list(string.punctuation)\n",
    "\n",
    "    tokens_no_stop = [token for token in tokens\n",
    "                        if token not in stop_list]            \n",
    "    \n",
    "#     # extract stem of the words\n",
    "#     stemmer = PorterStemmer()\n",
    "#     tokens_stem = [stemmer.stem(token) for token in tokens_no_stop]\n",
    "\n",
    "    # use lemma instead\n",
    "    # reason: remove the influence of plural or tense\n",
    "    # but retain the subtle difference in legal writting\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lemma = [lemmatizer.lemmatize(token) for token in tokens_no_stop]\n",
    "    \n",
    "    # remove numbers (the actual values are not useful)\n",
    "    tokens_no_num = []\n",
    "    for token in tokens_lemma:\n",
    "        try:\n",
    "            float(token)\n",
    "        except:\n",
    "            tokens_no_num.append(token)\n",
    "    \n",
    "    return tokens_no_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenize_clean the data for word2vec training\n",
    "\n",
    "cleaned_text = []\n",
    "for i in range(train_data.shape[0]):\n",
    "    tokens = tokenize_cleaning(train_data['claims'].iloc[i])\n",
    "    cleaned_text.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21202"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Word2Vec(cleaned_text, size=100, window=5, min_count=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'polypeptide', 0.693970799446106),\n",
       " (u'glycoprotein', 0.6489318609237671),\n",
       " (u'subunit', 0.6218897104263306),\n",
       " (u'adp', 0.6021888256072998),\n",
       " (u'repressor', 0.5989565849304199),\n",
       " (u'kinase', 0.5918909311294556),\n",
       " (u'fusion', 0.5866469740867615),\n",
       " (u'mbp', 0.5858468413352966),\n",
       " (u'translocation', 0.5848914980888367),\n",
       " (u'kda', 0.5842524766921997)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['protein'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'processor', 0.696655809879303),\n",
       " (u'microprocessor', 0.6668151617050171),\n",
       " (u'software', 0.6461315155029297),\n",
       " (u'executable', 0.6111671924591064),\n",
       " (u'computer-readable', 0.6046246886253357),\n",
       " (u'sub-code', 0.6031157970428467),\n",
       " (u'electronically', 0.6021907925605774),\n",
       " (u'program', 0.5960052013397217),\n",
       " (u'hyperlink', 0.5921428203582764),\n",
       " (u'programmed', 0.5846973061561584)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(positive=['computer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save the word2vec model\n",
    "model.save('models/word2vec_claims_final')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training using the word2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the word2vec model\n",
    "model = Word2Vec.load('models/word2vec_claims_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12033, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from 2004-2007\n",
    "years = np.arange(2004, 2008)\n",
    "\n",
    "# dataframe to store the results\n",
    "claims = pd.DataFrame()\n",
    "\n",
    "# import the abstract from each table\n",
    "for year in years:\n",
    "    # query:\n",
    "    sql_query = \"\"\"\n",
    "    SELECT claims, id, payment_times, classification\n",
    "        FROM patents_%s;\n",
    "    \"\"\" %str(year)\n",
    "\n",
    "    results = pd.read_sql_query(sql_query,con)\n",
    "    \n",
    "    claims = pd.concat([claims, results], axis = 0)\n",
    "    \n",
    "# check size of the data\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 4)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the patents missing classification data\n",
    "missing_class_index = (claims['classification'].values == 'NA')\n",
    "\n",
    "# reassign patent index\n",
    "claims.index = range(len(claims.index))\n",
    "# drop the rows\n",
    "claims =  claims.drop(claims.index[missing_class_index])\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = y_data[claims['classification'].values != 'NA']\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize_clean for training the final model\n",
    "\n",
    "cleaned_text = []\n",
    "for i in range(claims.shape[0]):\n",
    "    tokens = tokenize_cleaning(claims['claims'].iloc[i])\n",
    "    cleaned_text.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compute average word-vector for a text\n",
    "def dec_vec(model, text):\n",
    "    # store the vector for each word\n",
    "    vectors = []\n",
    "    \n",
    "    # compute on each word\n",
    "    for j in range(len(text)):\n",
    "        try:\n",
    "            vectors.append(model.wv[text[j]])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not vectors:\n",
    "        vectors_mean = np.zeros((1, 100))\n",
    "    else:\n",
    "        vectors_mean = np.nanmean(vectors, axis = 0)\n",
    "        vectors_mean = vectors_mean.reshape((1, 100))\n",
    "    \n",
    "    # return vector mean\n",
    "    return vectors_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 100)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_vec = np.zeros((1, 100))\n",
    "\n",
    "for i in range(claims.shape[0]):\n",
    "    vec = dec_vec(model, cleaned_text[i])\n",
    "    claims_vec = np.concatenate([claims_vec, vec], axis = 0)\n",
    "    \n",
    "claims_vec = claims_vec[1:, :]\n",
    "claims_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "x_train:  (10030, 100)\n",
      "x_test:  (2000, 100)\n",
      "y_train:  (10030,)\n",
      "y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "# split the training and testing data\n",
    "# split train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(claims_vec, y_data, \n",
    "                                                    test_size = 2000, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "print \"Dataset dimensions:\"\n",
    "print \"x_train: \", x_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"y_test: \", y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8217, 100)\n",
      "(8217,)\n"
     ]
    }
   ],
   "source": [
    "# sample the same number of'useful' patents as the 'not useful' patents\n",
    "# size of each class\n",
    "num_size = np.sum(y_data == 0)\n",
    "\n",
    "#random shuffle the rows\n",
    "n = x_train.shape[0]\n",
    "perm = range(n)\n",
    "np.random.shuffle(perm)\n",
    "\n",
    "x_train = x_train[perm]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# separate the two classes\n",
    "x_useful = x_train[y_train == 1, :]\n",
    "x_not_useful = x_train[y_train == 0, :]\n",
    "y_useful = y_train[y_train == 1]\n",
    "y_not_useful = y_train[y_train == 0]\n",
    "\n",
    "# sample num_size from the 'useful' class\n",
    "x_useful = x_useful[:num_size]\n",
    "y_useful = y_useful[:num_size]\n",
    "\n",
    "# combine the two classes\n",
    "x_data_sub = np.concatenate((x_useful, x_not_useful), axis = 0)\n",
    "y_data_sub = np.concatenate((y_useful, y_not_useful), axis = 0)\n",
    "\n",
    "# shuffle again\n",
    "# shuffle the combined data\n",
    "n2 = x_data_sub.shape[0]\n",
    "perm2 = range(n2)\n",
    "np.random.shuffle(perm2)\n",
    "\n",
    "x_data_sub = x_data_sub[perm2]\n",
    "y_data_sub = y_data_sub[perm2]\n",
    "\n",
    "# check the size\n",
    "print x_data_sub.shape\n",
    "print y_data_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "x_train_std = scaler.fit_transform(x_data_sub)\n",
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### tune random forest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 8, 2)\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space}, \n",
    "                          cv  = 5, scoring = 'accuracy')\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_std, y_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.542168674699\n",
      "Best parameter:  {'max_features': 6}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.587\n",
      "F1 score:  0.694526627219\n",
      "Precision:  0.658947368421\n",
      "Recall:  0.734167318217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[235, 486],\n",
       "       [340, 939]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_std, y_data_sub)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_std)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write my own scoring function\n",
    "def my_loss_func(y_actual, y_pred):\n",
    "    \n",
    "    # set the price of applying for each patent\n",
    "    patent_cost = 10\n",
    "    \n",
    "    # set the value of a useful patent\n",
    "    useful_value = 15\n",
    "    \n",
    "    total_cost = np.sum(y_pred == 1) * patent_cost\n",
    "    total_value = np.sum((y_actual == 1) & (y_pred == 1)) * useful_value\n",
    "    \n",
    "    profit = total_value -  total_cost\n",
    "    \n",
    "    return profit\n",
    "\n",
    "my_scorer = make_scorer(my_loss_func, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### tune random forest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 8, 2)\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space}, \n",
    "                          cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_std, y_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: -1737.0335889\n",
      "Best parameter:  {'max_features': 6}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.584\n",
      "F1 score:  0.689552238806\n",
      "Precision:  0.659528907923\n",
      "Recall:  0.722439405786\n",
      "Net value:  -150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[244, 477],\n",
       "       [355, 924]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_std, y_data_sub)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_std)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tune class weight of random forest\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 8, 2)\n",
    "\n",
    "# add class weight tuning to the random forest model\n",
    "weights = np.logspace(-3,3,7)\n",
    "weight_list_dict = [{0:1, 1: weights[i]} for i in range(len(weights))]\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space,\n",
    "                                       'class_weight': weight_list_dict}, \n",
    "                          cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_std, y_data_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: -1347.00073019\n",
      "Best parameter:  {'max_features': 2, 'class_weight': {0: 1, 1: 1000.0}}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5395\n",
      "F1 score:  0.613187736245\n",
      "Precision:  0.662431941924\n",
      "Recall:  0.570758405004\n",
      "Net value:  -70\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[349, 372],\n",
       "       [549, 730]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_std, y_data_sub)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_std)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.6395\n",
      "F1 score:  0.780115888991\n",
      "Precision:  0.6395\n",
      "Recall:  1.0\n",
      "Net value:  -815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[   0,  721],\n",
       "       [   0, 1279]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if everything is predicted to be useful (benchmark)\n",
    "y_pred_uniform = np.ones(y_pred.shape)\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred_uniform == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred_uniform)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred_uniform)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred_uniform)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred_uniform)\n",
    "metrics.confusion_matrix(y_test, y_pred_uniform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5475\n",
      "F1 score:  0.647722849358\n",
      "Precision:  0.64496124031\n",
      "Recall:  0.650508209539\n",
      "Net value:  -420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[263, 458],\n",
       "       [447, 832]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if randomly assign the two classes with the same ratio\n",
    "y_pred_random = np.random.uniform(0, 1, size = y_test.shape[0])\n",
    "# turn into binary\n",
    "y_random_class = np.zeros(y_test.shape[0]) \n",
    "y_random_class[y_pred_random > 1- np.mean(y_test)] = 1\n",
    "\n",
    "print \"Test accuracy: \", np.mean(y_random_class == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_random_class, y_test)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_random_class)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_random_class)\n",
    "print \"Net value: \", my_loss_func(y_test, y_random_class)\n",
    "metrics.confusion_matrix(y_test, y_random_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
