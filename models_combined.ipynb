{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "# SQL related packages\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy_utils import database_exists, create_database\n",
    "import psycopg2\n",
    "# sklearn packages\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.linear_model import LogisticRegression as Log\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "# text analysis packages\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the non-text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read the data with the non-text features\n",
    "patents = pd.read_pickle(\"patent_data/nontext_features_addwordcounts.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12030, 21)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>publication_year</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>...</th>\n",
       "      <th>num_patent_citations</th>\n",
       "      <th>num_nonpatent_citations</th>\n",
       "      <th>num_claims</th>\n",
       "      <th>num_similar_doc</th>\n",
       "      <th>num_authors</th>\n",
       "      <th>payment_times</th>\n",
       "      <th>words_title</th>\n",
       "      <th>words_abstract</th>\n",
       "      <th>words_description</th>\n",
       "      <th>words_claims</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US6699658B1</td>\n",
       "      <td>Yeast cell surface display of proteins and use...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>207</td>\n",
       "      <td>519781</td>\n",
       "      <td>954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US6699724B1</td>\n",
       "      <td>Metal nanoshells for biosensing applications</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>44</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>179</td>\n",
       "      <td>71698</td>\n",
       "      <td>407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US6690816B2</td>\n",
       "      <td>Systems and methods for tubular object process...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>114</td>\n",
       "      <td>122503</td>\n",
       "      <td>1105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US6711436B1</td>\n",
       "      <td>Compositions, apparatus and methods for facili...</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>109</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>290</td>\n",
       "      <td>316007</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US6711432B1</td>\n",
       "      <td>Computer-aided orthopedic surgery</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>114</td>\n",
       "      <td>44</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>49083</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                                              title  \\\n",
       "0  US6699658B1  Yeast cell surface display of proteins and use...   \n",
       "1  US6699724B1      Metal nanoshells for biosensing applications    \n",
       "2  US6690816B2  Systems and methods for tubular object process...   \n",
       "3  US6711436B1  Compositions, apparatus and methods for facili...   \n",
       "4  US6711432B1                 Computer-aided orthopedic surgery    \n",
       "\n",
       "   publication_year  B  C  D  E  F  G  H      ...       num_patent_citations  \\\n",
       "0              2004  0  1  0  0  0  0  0      ...                         28   \n",
       "1              2004  0  0  0  0  0  1  0      ...                         47   \n",
       "2              2004  0  0  0  0  0  1  0      ...                          9   \n",
       "3              2004  0  0  0  0  0  0  0      ...                        105   \n",
       "4              2004  0  0  0  0  0  0  0      ...                         15   \n",
       "\n",
       "   num_nonpatent_citations  num_claims  num_similar_doc  num_authors  \\\n",
       "0                       34          42                1            4   \n",
       "1                       44          25                0            4   \n",
       "2                        0          32                1            4   \n",
       "3                      109          45                7            1   \n",
       "4                      114          44                3            4   \n",
       "\n",
       "   payment_times  words_title  words_abstract  words_description  words_claims  \n",
       "0              3           10             207             519781           954  \n",
       "1              3            6             179              71698           407  \n",
       "2              1            8             114             122503          1105  \n",
       "3              3            9             290             316007           196  \n",
       "4              3            4             139              49083           683  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print patents.shape\n",
    "patents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of patents with > 1 maintenance fee payments:  0.62859517872\n"
     ]
    }
   ],
   "source": [
    "# reformat the response variable into binary\n",
    "y_data = np.zeros(patents.shape[0])\n",
    "y_data[patents['payment_times'].values >= 2] = 1\n",
    "\n",
    "print \"Percentage of patents with > 1 maintenance fee payments: \", np.mean(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 17)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictors\n",
    "x_data = patents.drop(['id', 'title', 'payment_times', 'publication_year'], axis = 1).values\n",
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load claims data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#access to sql database\n",
    "dbname = 'patent_db'\n",
    "username = 'jy'\n",
    "pswd = 'jy'\n",
    "\n",
    "engine = create_engine('postgresql://%s:%s@localhost/%s'%(username,pswd,dbname))\n",
    "\n",
    "# reading from sql database\n",
    "# connect:\n",
    "con = None\n",
    "con = psycopg2.connect(database = dbname, user = username, host='localhost', password=pswd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12033, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from 2004-2007\n",
    "years = np.arange(2004, 2008)\n",
    "\n",
    "# dataframe to store the results\n",
    "claims = pd.DataFrame()\n",
    "\n",
    "# import the abstract from each table\n",
    "for year in years:\n",
    "    # query:\n",
    "    sql_query = \"\"\"\n",
    "    SELECT claims, id, payment_times, classification\n",
    "        FROM patents_%s;\n",
    "    \"\"\" %str(year)\n",
    "\n",
    "    results = pd.read_sql_query(sql_query,con)\n",
    "    \n",
    "    claims = pd.concat([claims, results], axis = 0)\n",
    "    \n",
    "# check size of the data\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy/anaconda2/envs/my_projects_env/lib/python2.7/site-packages/pandas/indexes/base.py:1434: VisibleDeprecationWarning: boolean index did not match indexed array along dimension 0; dimension is 12030 but corresponding boolean dimension is 12033\n",
      "  result = getitem(key)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12030, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the patents missing classification data\n",
    "missing_class_index = (claims['classification'].values == 'NA')\n",
    "\n",
    "# reassign patent index\n",
    "claims.index = range(len(claims.index))\n",
    "# drop the rows\n",
    "claims =  claims.drop(patents.index[missing_class_index])\n",
    "claims.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_cleaning(text):\n",
    "    # tokenize the text first\n",
    "    tokens = word_tokenize(text.decode('utf-8'))\n",
    "    \n",
    "    # lowercase all the words\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    \n",
    "    # clean up stop words and punctuations \n",
    "    stop_list = stopwords.words('english') + list(string.punctuation)\n",
    "\n",
    "    tokens_no_stop = [token for token in tokens\n",
    "                        if token not in stop_list]            \n",
    "    \n",
    "#     # extract stem of the words\n",
    "#     stemmer = PorterStemmer()\n",
    "#     tokens_stem = [stemmer.stem(token) for token in tokens_no_stop]\n",
    "\n",
    "    # use lemma instead\n",
    "    # reason: remove the influence of plural or tense\n",
    "    # but retain the subtle difference in legal writting\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens_lemma = [lemmatizer.lemmatize(token) for token in tokens_no_stop]\n",
    "    \n",
    "    # remove numbers (the actual values are not useful)\n",
    "    tokens_no_num = []\n",
    "    for token in tokens_lemma:\n",
    "        try:\n",
    "            float(token)\n",
    "        except:\n",
    "            tokens_no_num.append(token)\n",
    "    \n",
    "    return tokens_no_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tokenize_clean the claims and count the occurence of the words\n",
    "\n",
    "cleaned_text = []\n",
    "for i in range(claims.shape[0]):\n",
    "    tokens = tokenize_cleaning(claims['claims'].iloc[i])\n",
    "    cleaned_text.append(' '.join(word for word in tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12030, 8035)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to bag-of-words\n",
    "# min number selected by examining the low-frequency words\n",
    "vectorizer = CountVectorizer(max_df = 0.4, min_df=5)\n",
    "\n",
    "# perform a count-based vectorization of the document\n",
    "word_vec = vectorizer.fit(cleaned_text)\n",
    "word_counts = word_vec.transform(cleaned_text)\n",
    "\n",
    "# convert to array\n",
    "word_counts = word_counts.toarray()\n",
    "word_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical words detected:  222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12030, 7813)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# still need to remove some number words \n",
    "# due to how CountVectorizer treats '-' and '/'\n",
    "\n",
    "# remove any word with numbers in it\n",
    "words = word_vec.get_feature_names()\n",
    "num_word_index = np.zeros(len(words))\n",
    "\n",
    "for i in range(len(words)):\n",
    "    word = words[i]\n",
    "    for j in range(len(word)):\n",
    "        try:\n",
    "            float(word[j])\n",
    "            num_word_index[i] = 1\n",
    "            break\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "print \"Number of numerical words detected: \", int(np.sum(num_word_index))\n",
    "\n",
    "# remove the number words\n",
    "words_no_num = np.asarray(words)[num_word_index == 0]\n",
    "word_counts = word_counts[:, num_word_index == 0]\n",
    "\n",
    "word_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# combine the claims data with the non-text features\n",
    "x_data = np.concatenate([x_data, word_counts], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dimensions:\n",
      "x_train:  (10030, 7830)\n",
      "x_test:  (2000, 7830)\n",
      "y_train:  (10030,)\n",
      "y_test:  (2000,)\n"
     ]
    }
   ],
   "source": [
    "# split train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size = 2000, \n",
    "                                                    random_state = 123)\n",
    "\n",
    "print \"Dataset dimensions:\"\n",
    "print \"x_train: \", x_train.shape\n",
    "print \"x_test: \", x_test.shape\n",
    "print \"y_train: \", y_train.shape\n",
    "print \"y_test: \", y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using subsampling to generate balanced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7468, 7830)\n",
      "(7468,)\n"
     ]
    }
   ],
   "source": [
    "### subsampling the training data\n",
    "# sample the same number of'useful' patents as the 'not useful' patents\n",
    "# size of each class\n",
    "num_size = np.sum(y_train == 0)\n",
    "\n",
    "#random shuffle the rows\n",
    "n = x_train.shape[0]\n",
    "perm = range(n)\n",
    "np.random.shuffle(perm)\n",
    "\n",
    "x_train = x_train[perm]\n",
    "y_train = y_train[perm]\n",
    "\n",
    "# separate the two classes\n",
    "x_useful = x_train[y_train == 1, :]\n",
    "x_not_useful = x_train[y_train == 0, :]\n",
    "y_useful = y_train[y_train == 1]\n",
    "y_not_useful = y_train[y_train == 0]\n",
    "\n",
    "# sample num_size from the 'useful' class\n",
    "x_useful = x_useful[:num_size]\n",
    "y_useful = y_useful[:num_size]\n",
    "\n",
    "# combine the two classes\n",
    "x_train_sub = np.concatenate((x_useful, x_not_useful), axis = 0)\n",
    "y_train_sub = np.concatenate((y_useful, y_not_useful), axis = 0)\n",
    "\n",
    "# shuffle again\n",
    "# shuffle the combined data\n",
    "n2 = x_train_sub.shape[0]\n",
    "perm2 = range(n2)\n",
    "np.random.shuffle(perm2)\n",
    "\n",
    "x_train_sub = x_train_sub[perm2]\n",
    "y_train_sub = y_train_sub[perm2]\n",
    "\n",
    "# check the size\n",
    "print x_train_sub.shape\n",
    "print y_train_sub.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jy/anaconda2/envs/my_projects_env/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# standardize the predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "x_train_std = scaler.fit_transform(x_train_sub)\n",
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA on the claims word-counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try dimensionality reduction using PCA\n",
    "pca = PCA()\n",
    "\n",
    "x_train_counts_pca = pca.fit_transform(x_train_std[:, 17:])\n",
    "x_test_counts_pca = pca.transform(x_test_std[:, 17:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs that can explain > 90% variability:  2481\n"
     ]
    }
   ],
   "source": [
    "# find the cum-variance explained at each level\n",
    "total_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_pc = np.where((total_var > 0.9) == True)[0][0]\n",
    "\n",
    "print \"The number of PCs that can explain > 90% variability: \", n_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine to the non-text features\n",
    "x_train_pca = np.concatenate([x_train_std[:, :17], x_train_counts_pca[:, :n_pc]], axis = 1)\n",
    "x_test_pca = np.concatenate([x_test_std[:, :17], x_test_counts_pca[:, :n_pc]], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write my own scoring function\n",
    "def my_loss_func(y_actual, y_pred):\n",
    "    \n",
    "    # set the price of applying for each patent\n",
    "    patent_cost = 10\n",
    "    \n",
    "    # set the value of a useful patent\n",
    "    useful_value = 15\n",
    "    \n",
    "    total_cost = np.sum(y_pred == 1) * patent_cost\n",
    "    total_value = np.sum((y_actual == 1) & (y_pred == 1)) * useful_value\n",
    "    \n",
    "    profit = total_value -  total_cost\n",
    "    \n",
    "    return profit\n",
    "\n",
    "my_scorer = make_scorer(my_loss_func, greater_is_better=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### use logistic regression\n",
    "\n",
    "# call the model function\n",
    "model = Log()\n",
    "# parameter tuning\n",
    "c =  np.logspace(-5, 5, 11)\n",
    "\n",
    "# use grid search with 5-fold CV\n",
    "grid_model = GridSearchCV(model, param_grid = {'C': c}, cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model.fit(x_train_pca, y_train_sub) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.564184495693\n",
      "Best parameter:  {'C': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.536575228595\n",
      "F1 score:  0.552747693542\n",
      "Precision:  0.720711297071\n",
      "Recall:  0.448275862069\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[602, 267],\n",
       "       [848, 689]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_log = grid_model.best_estimator_\n",
    "best_log.fit(x_train_pca, y_train_sub)\n",
    "\n",
    "y_pred = best_log.predict(x_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_pred, y_test)\n",
    "print \"Precision: \", metrics.precision_score(y_pred, y_test)\n",
    "print \"Recall: \", metrics.recall_score(y_pred, y_test)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = Log()\n",
    "\n",
    "# parameter tuning\n",
    "c =  np.logspace(-5, 3, 9)\n",
    "\n",
    "# add class weight tuning to the random forest model\n",
    "weights = np.logspace(-4,0,5)\n",
    "weight_list_dict = [{0:1, 1: weights[i]} for i in range(len(weights))]\n",
    "\n",
    "# use grid search with 5-fold CV\n",
    "grid_model = GridSearchCV(model, param_grid = {'C': c,'class_weight': weight_list_dict}, \n",
    "                          cv  = 5, scoring = 'f1')\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 0.528970792818\n",
      "Best parameter:  {'C': 1.0, 'class_weight': {0: 1, 1: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.540315876974\n",
      "F1 score:  0.586077844311\n",
      "Precision:  0.68986784141\n",
      "Recall:  0.509433962264\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[517, 352],\n",
       "       [754, 783]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_log = grid_model.best_estimator_\n",
    "best_log.fit(x_train_pca, y_train_sub)\n",
    "\n",
    "y_pred = best_log.predict(x_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### tune random forest\n",
    "\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 10, 2)\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space}, \n",
    "                          cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: -1608.98232458\n",
      "Best parameter:  {'max_features': 8}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5035\n",
      "F1 score:  0.558470431303\n",
      "Precision:  0.496050552923\n",
      "Recall:  0.638860630722\n",
      "Net value:  -410\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[379, 355],\n",
       "       [638, 628]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_pca, y_train_sub)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_pred, y_test)\n",
    "print \"Precision: \", metrics.precision_score(y_pred, y_test)\n",
    "print \"Recall: \", metrics.recall_score(y_pred, y_test)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tuning class weight\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 10, 2)\n",
    "\n",
    "# add class weight tuning to the random forest model\n",
    "weights = np.logspace(-4,0,5)\n",
    "weight_list_dict = [{0:1, 1: weights[i]} for i in range(len(weights))]\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space,\n",
    "                                       'class_weight': weight_list_dict}, \n",
    "                          cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca, y_train_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: -1584.99196572\n",
      "Best parameter:  {'max_features': 8, 'class_weight': {0: 1, 1: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.5035\n",
      "F1 score:  0.556894243641\n",
      "Precision:  0.492890995261\n",
      "Recall:  0.64\n",
      "Net value:  -390\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[383, 351],\n",
       "       [642, 624]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_pca, y_train_sub)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_pred, y_test)\n",
    "print \"Precision: \", metrics.precision_score(y_pred, y_test)\n",
    "print \"Recall: \", metrics.recall_score(y_pred, y_test)\n",
    "print \"Net value: \", my_loss_func(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the rf model\n",
    "pickle.dump(best_rf, open(\"models/best_rf_combined.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pickle the pca and scaler\n",
    "pickle.dump(pca, open(\"models/best_rf_pca.p\", 'wb'))\n",
    "pickle.dump(scaler, open(\"models/best_rf_scaler.p\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## try open the model and predict\n",
    "#rf = pickle.load(open(\"models/best_rf.p\", 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly work on the imbalanced training data + tune class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# standardize the predictors\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "x_train_std = scaler.fit_transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# try dimensionality reduction using PCA\n",
    "pca = PCA()\n",
    "\n",
    "x_train_counts_pca = pca.fit_transform(x_train_std[:, 13:])\n",
    "x_test_counts_pca = pca.transform(x_test_std[:, 13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of PCs that can explain > 90% variability:  2797\n"
     ]
    }
   ],
   "source": [
    "# find the cum-variance explained at each level\n",
    "total_var = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_pc = np.where((total_var > 0.9) == True)[0][0]\n",
    "\n",
    "print \"The number of PCs that can explain > 90% variability: \", n_pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine to the non-text features\n",
    "x_train_pca = np.concatenate([x_train_std[:, :13], x_train_counts_pca[:, :n_pc]], axis = 1)\n",
    "x_test_pca = np.concatenate([x_test_std[:, :13], x_test_counts_pca[:, :n_pc]], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest + tuning class weight\n",
    "model = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "# tune max_features\n",
    "param_space = np.arange(2, 8, 2)\n",
    "\n",
    "# add class weight tuning to the random forest model\n",
    "weights = np.logspace(0,4,5)\n",
    "weight_list_dict = [{0:1, 1: weights[i]} for i in range(len(weights))]\n",
    "\n",
    "grid_model = GridSearchCV(model, n_jobs = 4, \n",
    "                          param_grid = {'max_features': param_space,\n",
    "                                       'class_weight': weight_list_dict}, \n",
    "                          cv  = 5, scoring = my_scorer)\n",
    "# fit on the data\n",
    "grid_model = grid_model.fit(x_train_pca, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best accuracy: 16588.0070657\n",
      "Best parameter:  {'max_features': 2, 'class_weight': {0: 1, 1: 1.0}}\n"
     ]
    }
   ],
   "source": [
    "# check results\n",
    "print \"Best accuracy:\", grid_model.best_score_\n",
    "print \"Best parameter: \", grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test accuracy:  0.63757273483\n",
      "F1 score:  0.770042194093\n",
      "Precision:  0.647450110865\n",
      "Recall:  0.949902407287\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[  74,  795],\n",
       "       [  77, 1460]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "best_rf = grid_model.best_estimator_\n",
    "best_rf.fit(x_train_pca, y_train)\n",
    "\n",
    "y_pred = best_rf.predict(x_test_pca)\n",
    "\n",
    "# accuracy\n",
    "print \"Test accuracy: \", np.mean(y_pred == y_test)\n",
    "print \"F1 score: \", metrics.f1_score(y_test, y_pred)\n",
    "print \"Precision: \", metrics.precision_score(y_test, y_pred)\n",
    "print \"Recall: \", metrics.recall_score(y_test, y_pred)\n",
    "metrics.confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
